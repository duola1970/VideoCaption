{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,os,time,math,os.path,datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python split() 通过指定分隔符对字符串进行切片，如果参数 num 有指定值，则分隔 num+1 个子字符串,返回分割后的字符串列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取时间戳，\n",
    "def time_stamp2time(x):\n",
    "    time_list = [str(i) for i in x.split(' --> ')]\n",
    "    time_list1_1 = [x for x in time_list[0].split(':')]\n",
    "    time_list1_2 = [int(x) for x in time_list1_1[2].split(',')]\n",
    "    time_list1_1.pop()\n",
    "\n",
    "    time_list2_1 = [x for x in time_list[1].split(':')]\n",
    "    time_list2_2 = [int(x) for x in time_list2_1[2].split(',')]\n",
    "    time_list2_1.pop()\n",
    "\n",
    "    t1=[int(time_list1_1[0]),int(time_list1_1[1]),(time_list1_2[0]+time_list1_2[1]/1000)]\n",
    "    t2=[int(time_list2_1[0]),int(time_list2_1[1]),(time_list2_2[0]+time_list2_2[1]/1000)]\n",
    "    return t1,t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回时间戳\n",
    "def time2time_stamp(x):\n",
    "    x.append(round((x[2]-math.floor(x[2])),3))\n",
    "    x[2] = math.floor(x[2])\n",
    "    H = str(x[0]).zfill(2)\n",
    "    M = str(x[1]).zfill(2)\n",
    "    S = str(x[2]).zfill(2)\n",
    "    MS = str(int(x[3]*1000)).zfill(3)\n",
    "    time_stamp = H+':'+M+':'+S+','+MS\n",
    "    return time_stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python strip() 方法用于移除字符串头尾指定的字符（默认为空格）或字符序列。                                                                      注意：该方法只能删除开头或是结尾的字符，不能删除中间部分的字符。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### re.match（）的概念是从头匹配一个符合规则的字符串，从起始位置开始匹配，匹配成功返回一个对象，未匹配成功返回None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0.39] [0, 0, 3.75]\n",
      "[0, 0, 4.339] [0, 0, 11.759]\n",
      "[0, 0, 8.88] [0, 0, 14.929]\n",
      "[0, 0, 11.759] [0, 0, 18.57]\n",
      "[0, 0, 14.929] [0, 0, 20.339]\n",
      "[0, 0, 18.57] [0, 0, 21.899]\n",
      "[0, 0, 20.339] [0, 0, 24.39]\n",
      "[0, 0, 21.899] [0, 0, 26.879]\n",
      "[0, 0, 24.39] [0, 0, 29.01]\n",
      "[0, 0, 26.879] [0, 0, 33.179]\n",
      "[0, 0, 29.01] [0, 0, 35.579]\n",
      "[0, 0, 33.179] [0, 0, 37.619]\n",
      "[0, 0, 35.579] [0, 0, 40.62]\n",
      "[0, 0, 37.619] [0, 0, 44.009]\n",
      "[0, 0, 40.619] [0, 0, 47.009]\n",
      "[0, 0, 44.009] [0, 0, 48.75]\n",
      "[0, 0, 47.009] [0, 0, 50.969]\n",
      "[0, 0, 48.75] [0, 0, 54.57]\n",
      "[0, 0, 50.969] [0, 0, 56.91]\n",
      "[0, 0, 54.57] [0, 0, 58.948]\n",
      "[0, 0, 56.909] [0, 1, 4.289]\n",
      "[0, 0, 58.948] [0, 1, 6.929]\n",
      "[0, 1, 4.29] [0, 1, 9.24]\n",
      "[0, 1, 6.93] [0, 1, 11.97]\n",
      "[0, 1, 9.239] [0, 1, 14.368]\n",
      "[0, 1, 11.969] [0, 1, 16.408]\n",
      "[0, 1, 14.368] [0, 1, 21.45]\n",
      "[0, 1, 16.409] [0, 1, 24.24]\n",
      "[0, 1, 21.45] [0, 1, 27.0]\n",
      "[0, 1, 24.239] [0, 1, 29.158]\n",
      "[0, 1, 27.0] [0, 1, 32.519]\n",
      "[0, 1, 29.159] [0, 1, 34.32]\n",
      "[0, 1, 32.519] [0, 1, 38.64]\n",
      "[0, 1, 34.319] [0, 1, 40.849]\n",
      "[0, 1, 38.64] [0, 1, 44.06]\n",
      "[0, 1, 40.849] [0, 1, 48.709]\n",
      "[0, 1, 44.06] [0, 1, 51.149]\n",
      "[0, 1, 48.709] [0, 1, 54.289]\n",
      "[0, 1, 51.149] [0, 1, 57.84]\n",
      "[0, 1, 54.29] [0, 2, 0.0]\n",
      "[0, 1, 57.84] [0, 2, 2.909]\n",
      "[0, 2, 0.0] [0, 2, 5.399]\n",
      "[0, 2, 2.909] [0, 2, 8.879]\n",
      "[0, 2, 5.399] [0, 2, 11.189]\n",
      "[0, 2, 8.879] [0, 2, 13.019]\n",
      "[0, 2, 11.189] [0, 2, 14.969]\n",
      "[0, 2, 13.019] [0, 2, 18.18]\n",
      "[0, 2, 14.969] [0, 2, 20.669]\n",
      "[0, 2, 18.18] [0, 2, 22.86]\n",
      "[0, 2, 20.669] [0, 2, 27.988]\n",
      "[0, 2, 22.86] [0, 2, 32.34]\n",
      "[0, 2, 27.989] [0, 2, 36.299]\n",
      "[0, 2, 32.34] [0, 2, 38.61]\n",
      "[0, 2, 36.299] [0, 2, 40.879]\n",
      "[0, 2, 38.61] [0, 2, 44.199]\n",
      "[0, 2, 40.879] [0, 2, 44.198]\n",
      "[0.39, 4.339, 8.88, 11.759, 14.929, 18.57, 20.339, 21.899, 24.39, 26.879, 29.01, 33.179, 35.579, 37.619, 40.619, 44.009, 47.009, 48.75, 50.969, 54.57, 56.909, 58.948, 64.29, 66.93, 69.239, 71.969, 74.368, 76.409, 81.45, 84.239, 87.0, 89.159, 92.519, 94.319, 98.64, 100.849, 104.06, 108.709, 111.149, 114.29, 117.84, 120.0, 122.909, 125.399, 128.879, 131.189, 133.019, 134.969, 138.18, 140.669, 142.86, 147.989, 152.34, 156.299, 158.61, 160.879] \n",
      " [3.75, 11.759, 14.929, 18.57, 20.339, 21.899, 24.39, 26.879, 29.01, 33.179, 35.579, 37.619, 40.62, 44.009, 47.009, 48.75, 50.969, 54.57, 56.91, 58.948, 64.289, 66.929, 69.24, 71.97, 74.368, 76.408, 81.45, 84.24, 87.0, 89.158, 92.519, 94.32, 98.64, 100.849, 104.06, 108.709, 111.149, 114.289, 117.84, 120.0, 122.909, 125.399, 128.879, 131.189, 133.019, 134.969, 138.18, 140.669, 142.86, 147.988, 152.34, 156.299, 158.61, 160.879, 164.199, 164.198]\n"
     ]
    }
   ],
   "source": [
    "#打开字幕文件，获取字幕的start、end\n",
    "start = []\n",
    "end = []\n",
    "with open(r'C:\\Users\\renfang\\Desktop\\text\\Temporary1.txt','r',encoding='utf-8') as f1:\n",
    "#     lines = f1.readlines()\n",
    "#     for i,line in enumerate(lines):\n",
    "#         if line=='\\n':\n",
    "#             continue\n",
    "#         txt.append(line.strip())\n",
    "        \n",
    "#     path,name = os.path.split(r'C:\\Users\\renfang\\Desktop\\text\\Temporary.txt')\n",
    "#     f2 = open(os.path.join(r'C:\\Users\\renfang\\Desktop\\text','Temporary1.txt'),'a')\n",
    "    for line in f1: \n",
    "        if re.match(r'\\d{1,2}:\\d{1,2}:\\d{1,2},\\d{1,3} --> \\d{1,2}:\\d{1,2}:\\d{1,2},\\d{3}',line):\n",
    "            line = line.strip()\n",
    "            time_stamp1 = line\n",
    "\n",
    "            t1,t2 = time_stamp2time(time_stamp1)\n",
    "            print(t1,t2)\n",
    "            t1 = round(t1[0]*3600+t1[1]*60+t1[2]*1,3)\n",
    "            start.append(t1)\n",
    "            t2 = round(t2[0]*3600+t2[1]*60+t2[2]*1,3)\n",
    "            end.append(t2)\n",
    "print(start,'\\n',end)\n",
    "# #             t1 = modifying_time(t1,s)\n",
    "# #             t2 = modifying_time(t2,s)\n",
    "\n",
    "#             time_stamp_1 = time2time_stamp(t1)\n",
    "#             time_stamp_2 = time2time_stamp(t2)\n",
    "#             time_stamp2=time_stamp_1+' --> '+time_stamp_2+'\\n'\n",
    "#             line = time_stamp2\n",
    "#         f2.write(line)\n",
    "#     f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用 * 号操作符，可以将元组解压为列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取字幕集的start,end，对应的index\n",
    "start_time = []\n",
    "end_time = []\n",
    "start_ind = []\n",
    "end_ind = []\n",
    "start_time.append(start[0])\n",
    "index = []\n",
    "ind = 0\n",
    "index.append(ind)\n",
    "for i,j in zip(start[1:],end):\n",
    "    if j >= i:\n",
    "        ind += 1\n",
    "        continue\n",
    "    else:\n",
    "        index.append(ind)\n",
    "        end_time.append(j)\n",
    "        start_time.append(i)\n",
    "        ind += 1\n",
    "        index.append(ind)\n",
    "end_time.append(end[-1])\n",
    "index.append(ind)\n",
    "for i in range(0,len(index),2):\n",
    "    start_ind.append(index[i])\n",
    "    end_ind.append(index[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.39, 4.339], [3.75, 164.198], [0, 0, 1, 55], [0, 1], [0, 55])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time,end_time,index,start_ind,end_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取字幕\n",
    "txt1 = []\n",
    "txt = []\n",
    "index = []\n",
    "with open(r'C:\\Users\\renfang\\Desktop\\text\\Temporary1.txt','r',encoding='utf-8') as f1:\n",
    "    lines = f1.readlines()\n",
    "    for i,line in enumerate(lines):\n",
    "        if line=='\\n':\n",
    "            continue\n",
    "        txt.append(line.strip())\n",
    "for i in range(len(txt)):\n",
    "    if i%3==0:\n",
    "        txt1.append(txt[i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取字幕集的单词数\n",
    "count = []\n",
    "for i,j in zip(start_ind,end_ind):\n",
    "    if i == j:\n",
    "        count1 = 0\n",
    "        ls = txt1[i].split(\" \")\n",
    "        count1 += len(ls)\n",
    "        count.append(count1)\n",
    "    else:\n",
    "        count2 = 0\n",
    "        for c in range(i,j+1):\n",
    "            ls = txt1[c].split(\" \")\n",
    "            count2 += len(ls)\n",
    "        count.append(count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 382]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Music]',\n",
       " 'basic luxury rules I guess you might',\n",
       " 'consider depending on the type of luxury',\n",
       " \"that you're doing if you're doing\",\n",
       " 'recreational shooting you want to be',\n",
       " \"very careful that there's nobody\",\n",
       " \"standing in front of you while you're\",\n",
       " \"shooting or you're not standing in front\",\n",
       " \"of somebody as they're shooting it's a\",\n",
       " \"very simple rule it's common sense\",\n",
       " 'basically obviously a bow is always',\n",
       " 'considered a weapon or low today we',\n",
       " \"don't consider it a weapon we consider\",\n",
       " 'it a means of participating in an',\n",
       " \"athletic sport it's as much of a weapon\",\n",
       " 'as a golf club or a hockey stick but you',\n",
       " 'know in any other sport there are',\n",
       " \"dangers and that you've got to be aware\",\n",
       " 'of in archery the dangers are very',\n",
       " 'apparent because when someone has a bow',\n",
       " \"and arrow in their hands you're aware of\",\n",
       " 'the danger right away and and you you',\n",
       " \"act accordingly if you're in an archery\",\n",
       " \"range obviously everybody's standing at\",\n",
       " \"the same line nobody's standing in front\",\n",
       " \"of someone else while they're shooting\",\n",
       " \"you don't walk in front of the line if\",\n",
       " \"somebody's shooting that also applies as\",\n",
       " \"well if you're shooting outdoors nobody\",\n",
       " 'should be in front of the shooter while',\n",
       " 'the shooter has a bow and an arrow in',\n",
       " \"his hands if you're hunting there are a\",\n",
       " 'whole set of other rules that are',\n",
       " 'concerned the Department of',\n",
       " 'Environmental Conservation actually',\n",
       " 'prescribes a lot of the rules of safety',\n",
       " 'in the in the hunting environment',\n",
       " 'treestand hunting',\n",
       " 'which is a very common part of',\n",
       " 'bowhunting is a very dangerous part of',\n",
       " \"it you've got to learn what to do and\",\n",
       " 'what not to do while climbing a tree in',\n",
       " \"order to be a bow hunter you've got to\",\n",
       " 'take 10 hours of a hunter safety course',\n",
       " 'and if you wanted to go with a bow',\n",
       " \"you've got to take an additional eight\",\n",
       " 'hours of a bow hunter safety course so',\n",
       " \"it's a total of 18 hours of Hunter and\",\n",
       " \"bow hunter safety that you've got to\",\n",
       " 'take mandatorily before you can get your',\n",
       " \"licence so there's a lot of preparation\",\n",
       " 'before you go into the woods when you',\n",
       " 'get your license you are well-versed in',\n",
       " \"the in the do's and the don'ts and then\",\n",
       " 'the safety of the sport',\n",
       " '[Music]']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t = np.zeros((1,2400))\n",
    "idx = []\n",
    "for i,start in enumerate(start_time):\n",
    "    start_i = int(start/0.375)\n",
    "    end_i = start_i + count[i]\n",
    "    t[:,start_i:end_i+1] = 1\n",
    "    idx.append((start_i,end_i))\n",
    "#     if end_i < int(end_time[i]/0.375):\n",
    "#         idx[i].append([0]*len(int(end_time[i]/0.375)-end_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (11, 393)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2400)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 掩掉当前词的后面所有词\n",
    "def subsequent_mask(size):\n",
    "    '''\n",
    "    in: size               Sc\n",
    "    out: (1, size, size)   (1,Sc,Sc)\n",
    "    '''\n",
    "    mask = torch.ones(1, size, size)\n",
    "    mask = torch.tril(mask, 0)    # 返回矩阵下三角部分，其余部分定义为0\n",
    "\n",
    "    return mask.byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 掩掉pad部分和当前词的后面所有词\n",
    "def mask(src, trg, pad_idx):\n",
    "    # masking the padding. src shape: (B, Sv) -> (B, 1, Sv)\n",
    "    src_mask = (src != pad_idx).unsqueeze(1)\n",
    "    if trg is not None:\n",
    "        trg_mask = (trg != pad_idx).unsqueeze(-2) & subsequent_mask(trg.size(-1)).type_as(src_mask.data)\n",
    "        print('trg_mask:\\n', trg_mask.shape)\n",
    "        return src_mask, trg_mask\n",
    "    else:\n",
    "        return src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_masks(feature_stacks, captions, modality, pad_idx):\n",
    "    masks = {}\n",
    "\n",
    "    if modality == 'audio_video_text':\n",
    "        assert len(feature_stacks['audio'].shape) == 3\n",
    "        if captions is None:\n",
    "            masks['A_mask'] = mask(feature_stacks['audio'][:, :, 0], None, pad_idx)\n",
    "            masks['V_mask'] = mask(feature_stacks['video'][:, :, 0], None, pad_idx)\n",
    "            masks['T_mask'] = mask(feature_stacks['text'][:, :, 0], None, pad_idx)\n",
    "        else:\n",
    "            masks['V_mask'], masks['C_mask'] = mask(feature_stacks['video'][:, :, 0], captions, pad_idx)\n",
    "            masks['A_mask'] = mask(feature_stacks['audio'][:, :, 0], None, pad_idx)\n",
    "            masks['T_mask'] = mask(feature_stacks['text'][:, :, 0], None, pad_idx)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(Q, K, V, Mask, dropout=None):\n",
    "    d_k = K.size(-1)\n",
    "    QKt = Q.matmul(K.transpose(-1,-2))\n",
    "    att = QKt/np.sqrt(d_k)\n",
    "    \n",
    "    if Mask is not None:\n",
    "        att = att.masked_fill(Mask == 0, -float('inf'))\n",
    "    \n",
    "    softmax = F.softmax(att, dim=-1)\n",
    "    out = softmax.matmul(V)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        out = dropout(out)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dout_p, seq_len=3660):\n",
    "        super(PositionalEncoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dout_p)\n",
    "\n",
    "        pos_enc_mat = np.zeros((seq_len, d_model))\n",
    "        odds = np.arange(0, d_model, 2)\n",
    "        evens = np.arange(1, d_model, 2)\n",
    "\n",
    "        for pos in range(seq_len):\n",
    "            pos_enc_mat[pos, odds] = np.sin(pos / (10000 ** (odds / d_model)))  # 替换pos行，odds列的数据\n",
    "            pos_enc_mat[pos, evens] = np.cos(pos / (10000 ** (evens / d_model)))\n",
    "\n",
    "        self.pos_enc_mat = torch.from_numpy(pos_enc_mat).unsqueeze(0)    # (1,3660,d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, S, d_model = x.shape       # (32,S,d_model)\n",
    "        print('s:\\n', S)\n",
    "        # torch.cuda.FloatTensor torch.FloatTensor\n",
    "        x = x + self.pos_enc_mat[:, :S, :].type_as(x)    # 位置矩阵与特征矩阵直接相加\n",
    "        x = self.dropout(x)\n",
    "        # same as input\n",
    "        return x       # (32,S,d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:\n",
      " 3500\n"
     ]
    }
   ],
   "source": [
    "feature_stacks = {}\n",
    "V = torch.randn(1,300,1024)\n",
    "A = torch.randn(1,800,128)\n",
    "T = torch.randn(1,2400,300)\n",
    "V[:,61:,:] = 1\n",
    "A[:,161:,:] = 1\n",
    "T[:,:2,:] = 1\n",
    "T[:,300:,:] = 1\n",
    "C = torch.randn(1, 35).long()\n",
    "caption_idx, caption_idx_y = C[:, :-1], C[:, 1:]\n",
    "feature_stacks['audio'] = A\n",
    "feature_stacks['video'] = V\n",
    "feature_stacks['text'] = T\n",
    "\n",
    "masks = make_masks(feature_stacks, None, 'audio_video_text', 1)\n",
    "masks1 = torch.cat((masks['V_mask'],masks['A_mask'],masks['T_mask']),-1)\n",
    "masks1 = masks1.unsqueeze(1)\n",
    "\n",
    "# 拼接前的纬度变化\n",
    "linear_v = nn.Linear(1024,1024)\n",
    "linear_a = nn.Linear(128,1024)\n",
    "linear_t = nn.Linear(300,1024)\n",
    "V = linear_v(V)\n",
    "A = linear_a(A)\n",
    "T = linear_t(T)\n",
    "\n",
    "# 拼接\n",
    "VAT = torch.cat((V,A,T),1)\n",
    "\n",
    "# 位置编码\n",
    "pos_enc_vat = PositionalEncoder(1024, 0.1) \n",
    "VAT1 = pos_enc_vat(VAT)\n",
    "\n",
    "# 1、Self-Attention\n",
    "# 在进行Self-Attention之前的层归一化操作\n",
    "norm = nn.LayerNorm(1024)\n",
    "VAT1 = norm(VAT1)\n",
    "\n",
    "# 多头处理\n",
    "Q, K, V = VAT1, VAT1, VAT1\n",
    "Q = Q.view(1, 3500, 4, 256).transpose(-2,-3)\n",
    "K = K.view(1, 3500, 4, 256).transpose(-2,-3)\n",
    "V = V.view(1, 3500, 4, 256).transpose(-2,-3)\n",
    "\n",
    "# 注意力机制\n",
    "Q_att = attention(Q, K, V, masks1)\n",
    "\n",
    "# 多头处理\n",
    "Q_att = Q_att.transpose(-2,-3).contiguous().view(1, 3500, 1024)\n",
    "\n",
    "# 残差连接???\n",
    "VAT1 = VAT1 + Q_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2308, -0.1454,  0.6416,  ..., -0.2255, -0.3067, -0.3917],\n",
       "         [-0.4189, -0.7420,  0.4821,  ...,  0.2162,  0.0679,  0.9089],\n",
       "         [ 0.4482, -0.1315,  1.2233,  ..., -0.3031, -0.2870,  0.2325],\n",
       "         ...,\n",
       "         [-0.5852,  0.0894,  0.1753,  ...,  0.3825, -0.7355,  0.1522],\n",
       "         [-0.5852,  0.0894,  0.1753,  ...,  0.3825, -0.7355,  0.1522],\n",
       "         [-0.5852,  0.0894,  0.1753,  ...,  0.3825, -0.7355,  0.1522]]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3393, -0.1863,  0.9205,  ..., -0.2851, -0.3636, -0.5253],\n",
       "         [-0.5455, -0.9502,  0.6354,  ...,  0.2777,  0.0935,  1.1259],\n",
       "         [ 0.5794, -0.1190,  1.5232,  ..., -0.3970, -0.3576,  0.2681],\n",
       "         ...,\n",
       "         [-0.5807,  0.1264,  0.1660,  ...,  0.4092, -0.7289,  0.0991],\n",
       "         [-0.5807,  0.1264,  0.1660,  ...,  0.4092, -0.7289,  0.0991],\n",
       "         [-0.5807,  0.1264,  0.1660,  ...,  0.4092, -0.7289,  0.0991]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
       "        dtype=torch.uint8),\n",
       " 'V_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0]]], dtype=torch.uint8),\n",
       " 'T_mask': tensor([[[0, 0, 1,  ..., 0, 0, 0]]], dtype=torch.uint8)}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3500, 1024])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "         ...,\n",
       "         [ 0.7680, -1.8578,  0.7088,  ..., -0.7449,  0.9316,  0.7951],\n",
       "         [ 0.7866,  0.9117,  1.0180,  ...,  0.2123,  1.6742, -0.2868],\n",
       "         [-0.1063, -0.7285, -0.5330,  ..., -0.9776,  0.2947, -0.0619]]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn(1,3,3)\n",
    "b=torch.randn(1,2,3)\n",
    "c=torch.randn(1,1,3)\n",
    "a[:,:2,:]=1\n",
    "b[:,1:,:]=1\n",
    "d=torch.cat((a,b,c),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000,  1.0000],\n",
       "         [ 0.7125, -0.0493,  0.2297]]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  1.0000,  1.0000],\n",
       "         [ 1.0000,  1.0000,  1.0000],\n",
       "         [-0.6533,  0.0042,  0.9642],\n",
       "         [ 1.7821, -1.0278,  0.2553],\n",
       "         [ 1.0000,  1.0000,  1.0000],\n",
       "         [ 0.1070,  1.2576,  0.9142]]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
